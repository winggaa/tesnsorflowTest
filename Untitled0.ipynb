{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv4sSzAZOD3opCt0vuMTWR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kOs0GKKQEsx"
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q_edGhyPvpJ"
      },
      "source": [
        "# 필요한 모듈 다운\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p98MuloE050"
      },
      "source": [
        "# 필요한 모듈 다운\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNfHFCAvlQ7m"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0nZFaaCDjKj"
      },
      "source": [
        " # 주피터 노트북 환경일때 뜨는 체크포인트 디렉토리 삭제\n",
        " rmdir /content/custom_dataset/train/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iO1Ii0jSOcN"
      },
      "source": [
        "  # 주피터 노트북 환경일때 뜨는 체크포인트 디렉토리 삭제\n",
        " rmdir /content/custom_dataset/test/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dplu1bMYOFnp"
      },
      "source": [
        "batch_size = 32  #\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "#데이터셋이 들어있는 폴더 불러오고 훈련시킬 사진 지정하기.\n",
        "data = tf.keras.preprocessing.image_dataset_from_directory('/content/custom_dataset',validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "   batch_size=batch_size)\n",
        "#데이터셋이 들어있는 폴더 불러오고 테스트할 사진폴더 지정및 분할. custom_dataset안에 클래스폴더 구별하기.\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/custom_dataset',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npiTFOkEa9c"
      },
      "source": [
        "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # 데이터 증진(augmentation)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
        "])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "data_dir = './custom_dataset'\n",
        "train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
        "test_datasets = datasets.ImageFolder(os.path.join(data_dir, 'test'), transforms_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "print('학습 데이터셋 크기:', len(train_datasets))\n",
        "print('테스트 데이터셋 크기:', len(test_datasets))\n",
        "\n",
        "class_names = train_datasets.classes\n",
        "print('클래스:', class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGHXx7X7Fxqa"
      },
      "source": [
        "def imshow(input, title):\n",
        "    # torch.Tensor를 numpy 객체로 변환\n",
        "    input = input.numpy().transpose((1, 2, 0))\n",
        "    # 이미지 정규화 해제하기\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    input = std * input + mean\n",
        "    input = np.clip(input, 0, 1)\n",
        "    # 이미지 출력\n",
        "    plt.imshow(input)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 학습 데이터를 배치 단위로 불러오기\n",
        "iterator = iter(train_dataloader)\n",
        "\n",
        "# 현재 배치를 이용해 격자 형태의 이미지를 만들어 시각화\n",
        "inputs, classes = next(iterator)\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyojnvDoUZk8"
      },
      "source": [
        "model = models.resnet34(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "# 전이 학습(transfer learning): 모델의 출력 뉴런 수를 3개로 교체하여 마지막 레이어 다시 학습\n",
        "model.fc = nn.Linear(num_features, 3)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOQvhinUUezD"
      },
      "source": [
        "num_epochs = 50\n",
        "model.train()\n",
        "start_time = time.time()\n",
        "\n",
        "# 전체 반복(epoch) 수 만큼 반복하며\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    # 배치 단위로 학습 데이터 불러오기\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 모델에 입력(forward)하고 결과 계산\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_datasets)\n",
        "    epoch_acc = running_corrects / len(train_datasets) * 100.\n",
        "\n",
        "    # 학습 과정 중에 결과 출력\n",
        "    print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHbkonpaXMP6"
      },
      "source": [
        "model.eval()\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    running_loss = 0.\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
        "        print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n",
        "        imshow(inputs.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    epoch_loss = running_loss / len(test_datasets)\n",
        "    epoch_acc = running_corrects / len(test_datasets) * 100.\n",
        "    print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N_33YyaHiTX"
      },
      "source": [
        "#몇개만 불러서 예측해보기.\n",
        "\n",
        "# from PIL import Image\n",
        "# image = Image.open('1.jpg')\n",
        "# image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     outputs = model(image)\n",
        "#     _, preds = torch.max(outputs, 1)\n",
        "#     imshow(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hB8KNF4HlCI"
      },
      "source": [
        "# 필요한 라이브러리 설치하기\n",
        "!pip install flask-ngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuCDqYnZ9JP5"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuzdPbf_Hnr5"
      },
      "source": [
        "import io\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "\n",
        "# 이미지를 읽어 결과를 반환하는 함수\n",
        "def get_prediction(image_bytes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image = transforms_test(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        imshow(image.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
        "\n",
        "    return class_names[preds[0]]\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        # 이미지 바이트 데이터 받아오기\n",
        "        file = request.files['file']\n",
        "        image_bytes = file.read()\n",
        "\n",
        "        # 분류 결과 확인 및 클라이언트에게 결과 반환\n",
        "        class_name = get_prediction(image_bytes=image_bytes)\n",
        "        print(\"결과:\", {'class_name': class_name})\n",
        "        return jsonify({'class_name': class_name})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9ct8s1XHqCV"
      },
      "source": [
        "#서버 실행\n",
        "run_with_ngrok(app)\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y--TL7pnKlj"
      },
      "source": [
        "# 이미지 cmd에서 받아오기\n",
        "# curl -X POST -F file=@{이미지 파일명} {Ngrok 서버 주소}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}